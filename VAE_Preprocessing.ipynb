{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15G12AxDz1ji"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "---\n",
        "\n",
        "This Colab file contains the data preprocessing phase used in the VAE system. The goal of this project is the generation of unconditional/conditional audio, for which a Variational Autoencoder has been used. The data used for training comes from a dataset of MIDI files: the Lakh Dataset. This dataset has multiple partitions; in the project, a \"cleansed\" subset was used.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMex7xeZoaor",
        "outputId": "5e8e7e87-4955-445c-c044-d47ee1adb7e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E: Package 'libfluidsynth1' has no installation candidate\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyfluidsynth (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: music21 in /usr/local/lib/python3.10/dist-packages (9.1.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from music21) (5.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from music21) (1.4.2)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.10/dist-packages (from music21) (3.0.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from music21) (3.7.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from music21) (10.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from music21) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from music21) (2.31.0)\n",
            "Requirement already satisfied: webcolors>=1.5 in /usr/local/lib/python3.10/dist-packages (from music21) (1.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->music21) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->music21) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->music21) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->music21) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->music21) (1.16.0)\n",
            "Collecting pypianoroll\n",
            "  Downloading pypianoroll-1.0.4-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pypianoroll) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pypianoroll) (1.11.4)\n",
            "Requirement already satisfied: pretty-midi>=0.2.8 in /usr/local/lib/python3.10/dist-packages (from pypianoroll) (0.2.10)\n",
            "Requirement already satisfied: matplotlib>=1.5 in /usr/local/lib/python3.10/dist-packages (from pypianoroll) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5->pypianoroll) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5->pypianoroll) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5->pypianoroll) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5->pypianoroll) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5->pypianoroll) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5->pypianoroll) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5->pypianoroll) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5->pypianoroll) (2.8.2)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.10/dist-packages (from pretty-midi>=0.2.8->pypianoroll) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty-midi>=0.2.8->pypianoroll) (1.16.0)\n",
            "Installing collected packages: pypianoroll\n",
            "Successfully installed pypianoroll-1.0.4\n"
          ]
        }
      ],
      "source": [
        "%apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "%pip install -qU pyfluidsynth pretty_midi\n",
        "%pip install music21\n",
        "%pip install pypianoroll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puztPxIyh3oV",
        "outputId": "be4397b0-34df-472e-fb8d-5922ee47b533"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfcYQM4qjTis",
        "outputId": "61487bd2-b804-452b-c292-9fb846354dfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pretty_midi\n",
        "import pypianoroll\n",
        "import tables\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "import music21\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import IPython.display\n",
        "from datetime import datetime\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "from tqdm.notebook import tqdm, trange\n",
        "\n",
        "import random\n",
        "import itertools\n",
        "root_dir = '/content/drive/MyDrive/ColabNotebooks/AsItSounds'\n",
        "data_dir = root_dir + '/Lakh Piano Dataset/lpd_5/lpd_5_cleansed'\n",
        "music_dataset_lpd_dir = root_dir + '/Music Dataset/midis/lmd_matched'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhR5l1SjNTa5"
      },
      "source": [
        "# Getting MIDI and Song Metadata\n",
        "\n",
        "Utility functions which map the ids of the Song Million Dataset to the midi and their respective paths in the Lakh Dataset. The midi are placed in a hierarchical folder structure that follows the corresponding msd_id."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ng13lLDrN8Za"
      },
      "outputs": [],
      "source": [
        "RESULTS_PATH = os.path.join(root_dir, 'Lakh Piano Dataset', 'Metadata')\n",
        "\n",
        "# Utility functions for retrieving paths from a msd_id (milion song dataset id)\n",
        "def msd_id_to_dirs(msd_id):\n",
        "    \"\"\"Given an MSD ID, generate the path prefix.\n",
        "    E.g. TRABCD12345678 -> A/B/C/TRABCD12345678\"\"\"\n",
        "    return os.path.join(msd_id[2], msd_id[3], msd_id[4], msd_id)\n",
        "\n",
        "# function for retrieving path of file h5 (metadata) from a msd_id\n",
        "def msd_id_to_h5(msd_id):\n",
        "    \"\"\"Given an MSD ID, return the path to the corresponding h5\"\"\"\n",
        "    return os.path.join(RESULTS_PATH, 'lmd_matched_h5',\n",
        "                        msd_id_to_dirs(msd_id) + '.h5')\n",
        "\n",
        "# Load the midi npz file from the LMD cleansed folder, given the msd_id and the md5\n",
        "def get_midi_npz_path(msd_id, midi_md5):\n",
        "    return os.path.join(data_dir,\n",
        "                        msd_id_to_dirs(msd_id), midi_md5 + '.npz')\n",
        "\n",
        "# Load the midi file from the Music Dataset folder\n",
        "def get_midi_path(msd_id, midi_md5):\n",
        "    return os.path.join(music_dataset_lpd_dir,\n",
        "                        msd_id_to_dirs(msd_id), midi_md5 + '.mid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n49fNCuA7jpV"
      },
      "source": [
        "We read the csv file that contains the mapping between the msd_ids and the lpd_ids, we save the result in a vector. After that we create two dictionaries that return the corresponding msd_id given lpd_id and vice versa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY-AyplDYXSm"
      },
      "outputs": [],
      "source": [
        "# Open the cleansed ids - cleansed file ids : msd ids\n",
        "cleansed_ids = pd.read_csv(os.path.join(root_dir, 'Lakh Piano Dataset', 'cleansed_ids.txt'), delimiter = '    ', header = None, engine ='python')\n",
        "lpd_to_msd_ids = {a:b for a, b in zip(cleansed_ids[0], cleansed_ids[1])}\n",
        "msd_to_lpd_ids = {a:b for a, b in zip(cleansed_ids[1], cleansed_ids[0])}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvA0rILJN9r9"
      },
      "source": [
        "# Genre Management\n",
        "\n",
        "The cell below creates a dictionary and dataframe that keeps track of the genre of each midi in the dataset. Each midi in fact has a reference music genre (Pop_Rock, Reggae, Blues and so on). It is possible that the midi also has a reference subgenre, in that eventuality it joins the genre and is considered as one music genre. In initial training this information is not used, but for conditional creation it may come in handy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGhaBVSOzweZ"
      },
      "outputs": [],
      "source": [
        "# Reading the genre annotations\n",
        "genre_file_dir = os.path.join(root_dir, 'Lakh Piano Dataset', 'msd_tagtraum_cd1.cls')\n",
        "ids = []\n",
        "genres = []\n",
        "\n",
        "with open(genre_file_dir) as f:\n",
        "    line = f.readline()\n",
        "    while line:\n",
        "\n",
        "        # Avoid the initial lines of the file\n",
        "        if line[0] != '#':\n",
        "          split = line.strip().split(\"\\t\")\n",
        "\n",
        "          # Single genre case\n",
        "          if len(split) == 2:\n",
        "            ids.append(split[0])\n",
        "            genres.append(split[1])\n",
        "          # Sub-genre case\n",
        "          elif len(split) == 3:\n",
        "            ids.append(split[0])\n",
        "            ids.append(split[0])\n",
        "            genres.append(split[1])\n",
        "            genres.append(split[2])\n",
        "        line = f.readline()\n",
        "\n",
        "# Dataframe and dictionary\n",
        "genre_df = pd.DataFrame(data={\"TrackID\": ids, \"Genre\": genres})\n",
        "genre_dict = genre_df.groupby('TrackID')['Genre'].apply(lambda x: x.tolist()).to_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07Le14xf4NVd"
      },
      "source": [
        "**Objects that we need**\n",
        "\n",
        "- cleansed_ids: dictionary of LPD file name : MSD file name\n",
        "- lmd_metadata: list of dictionaries - each dict has a msd_id field to identify\n",
        "- Get the lmd_file_name (actual path )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CE9yQIuE9J5J"
      },
      "source": [
        "#Building the Dataset\n",
        "\n",
        "From the entire Lakh Cleansed Dataset we randomly take a number of songs, the process that will follow is to save and clean these chosen songs. We use the previously defined dictionary specifically msd_to_lpd. In a list we save all the keys and from that same list we randomly select our ids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-yNVTuosW92",
        "outputId": "1650fc1f-1a4b-4525-a062-94c844c5091a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of samples: 21425\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total number of samples: {len(msd_to_lpd_ids.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH9iHomJNVFI"
      },
      "source": [
        "We had to choose between one of these cells to select a random sample from  the entire dataset or the entire dataset instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wU0th4Rt5ZMu"
      },
      "outputs": [],
      "source": [
        "# Randomly choose 1000 songs out of these\n",
        "train_ids = random.choices(list(msd_to_lpd_ids.keys()), k = 10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pl81nmxTszkj"
      },
      "outputs": [],
      "source": [
        "train_ids = list(msd_to_lpd_ids.keys()) # full dataset loading (~21.000 songs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTsfktEd2HNu"
      },
      "source": [
        "For each of these retrieved ids we retrieve the name of the corresponding lpd file. With the latter, the previously defined utility functions are used, taking the path to the corresponding midi file. At this point with the use of the pypianoroll library we take the midi through the path and convert it to the pianoroll format, the result will be a pianoroll of 5 tracks, that is, 5 different instruments (Piano, Guitar, Bass, Strings, Drums).\n",
        "\n",
        "A resolution of 2 was used; the resolution defines the number of ticks per quarter note (beat). This setting is crucial in determining the temporal precision with which notes within a MIDI track are represented.\n",
        "\n",
        "A dictionary noting the various traces in the pianoroll was used to construct the tensors that will be given as input to the network. By doing so, it was possible to combine all 5 of them into a single tensor. In case one of the traces was empty, a bogus empty trace was placed in the tensor, and the corresponding tensor was marked as “having empty traces.” Only tensors which don't have empty traces were placed in a list\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "collapsed": true,
        "id": "1xM2flv96PUg",
        "outputId": "b5b235b5-c084-4c27-8fa3-3c6c46366331"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/21425 [00:00<?, ?it/s]<ipython-input-10-8674826de193>:47: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
            "  combined_pianoroll = torch.tensor([parts['piano_part'], parts['guitar_part'], parts['bass_part'], parts['strings_part'], parts['drums_part']])\n",
            "<ipython-input-10-8674826de193>:47: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  combined_pianoroll = torch.tensor([parts['piano_part'], parts['guitar_part'], parts['bass_part'], parts['strings_part'], parts['drums_part']])\n",
            "  2%|▏         | 447/21425 [07:52<6:09:50,  1.06s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8674826de193>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mnpz_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_midi_npz_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsd_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlpd_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m#print(npz_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mmultitrack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpypianoroll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpz_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0;31m#print(multitrack)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mmultitrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_resolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_to_same\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pypianoroll/inputs.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mloaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"info.json\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot find `info.json` in the NPZ file.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "combined_pianorolls = []\n",
        "i = 0\n",
        "for msd_file_name in tqdm(train_ids):\n",
        "\n",
        "  lpd_file_name = msd_to_lpd_ids[msd_file_name]\n",
        "  # Get the NPZ path\n",
        "  npz_path = get_midi_npz_path(msd_file_name, lpd_file_name)\n",
        "  #print(npz_path)\n",
        "  multitrack = pypianoroll.load(npz_path)\n",
        "  #print(multitrack)\n",
        "  multitrack.set_resolution(2).pad_to_same()\n",
        "  #print(multitrack)\n",
        "\n",
        "  # Piano, Guitar, Bass, Strings, Drums\n",
        "  # Splitting into different parts\n",
        "\n",
        "  parts = {'piano_part': None, 'guitar_part': None, 'bass_part': None, 'strings_part': None, 'drums_part': None}\n",
        "  song_length = None\n",
        "  empty_array = None\n",
        "  has_empty_parts = False\n",
        "  for track in multitrack.tracks:\n",
        "    #print(track.pianoroll.shape)\n",
        "    #print(track.pianoroll)\n",
        "    if track.name == 'Drums':\n",
        "      parts['drums_part'] = track.pianoroll\n",
        "    if track.name == 'Piano':\n",
        "      parts['piano_part'] = track.pianoroll\n",
        "    if track.name == 'Guitar':\n",
        "      parts['guitar_part'] = track.pianoroll\n",
        "    if track.name == 'Bass':\n",
        "      parts['bass_part'] = track.pianoroll\n",
        "    if track.name == 'Strings':\n",
        "      parts['strings_part'] = track.pianoroll\n",
        "    if track.pianoroll.shape[0] > 0:\n",
        "      empty_array = np.zeros_like(track.pianoroll)\n",
        "      #print(empty_array)\n",
        "      #print(track.pianoroll)\n",
        "\n",
        "  for k,v in parts.items():\n",
        "    if v.shape[0] == 0:\n",
        "      parts[k] = empty_array.copy()\n",
        "      has_empty_parts = True\n",
        "\n",
        "  # Stack all together - Piano, Guitar, Bass, Strings, Drums\n",
        "  combined_pianoroll = torch.tensor([parts['piano_part'], parts['guitar_part'], parts['bass_part'], parts['strings_part'], parts['drums_part']])\n",
        "  #print(combined_pianoroll.shape)\n",
        "\n",
        "  # These contain velocity information - the force with which the notes are hit - which can be standardized to 0/1 if we want (to compress)\n",
        "  if has_empty_parts == False:\n",
        "    combined_pianorolls.append(combined_pianoroll)\n",
        "    #print(combined_pianorolls.size())\n",
        "    i+=1\n",
        "    #print(i)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT1EDJhuIzq4"
      },
      "source": [
        "# Saving Files\n",
        "\n",
        "The final steps in this preprocessing are to save in two .pt files both the planorolls of our final dataset and their relative lengths. Then the lengths are taken and saved in a list, while the tensors of each planoroll are joined thanks to the torch.hstack method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-TeycNi6YyCm",
        "outputId": "0239ae01-562a-43ae-c02e-4059a9b82950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1018, 763, 845, 863, 129, 743, 1089, 1117, 1297, 658, 177, 825, 977, 465, 697, 747, 1113, 993, 1105, 974, 525, 1560, 881, 441, 671, 1297, 473, 911, 593, 793, 737, 1097, 590, 665, 1159, 841, 649, 779, 669, 573, 617, 1206, 733, 818, 1681, 585, 156, 739, 1358, 1411, 711, 640, 473, 932, 1265, 1113, 805, 545, 906, 926, 1345, 609, 601, 161, 1040, 675, 651, 867, 1049, 625, 1049, 875, 743, 1099, 193, 922, 689, 1145, 753, 853, 935, 914, 817, 193, 1026, 129, 905, 126, 949, 1000, 1185, 653, 1115, 129, 977, 392, 872, 971, 561, 361, 841, 1087, 715, 2153, 2187, 1233, 497, 615, 808, 1003, 1009, 1266, 721, 1208, 633, 345, 489, 838, 487, 2273, 817, 664, 361, 923, 768, 709, 869, 765, 1306, 545, 939, 481, 1369, 485, 801, 887, 888, 985, 1078, 1001, 1371, 841, 1045, 841, 474, 561, 1007, 577, 992, 1037, 706, 672, 889, 969, 1161, 390, 557, 1033, 345, 977, 1369, 1361, 1285, 561, 97, 1113, 569, 1117, 753, 944, 1053, 504, 735, 624, 297, 1362, 1385, 336, 944, 504, 857, 698, 733, 825, 907, 1155, 129, 785, 570, 1009, 760, 1094, 907, 886, 791, 1185, 1115, 978, 289, 513, 987, 608, 849, 745, 441, 536, 431, 557, 344, 907, 711, 993, 895, 616, 332, 299, 793, 1033, 913, 698, 322, 829, 453, 1095, 1634, 633, 1209, 1102, 873, 962, 647, 129, 904, 737, 361, 335, 769, 882, 609, 791, 681, 706, 430, 399, 865, 1203, 723, 861, 1266, 585, 1115, 737, 1096, 1155, 540, 676, 953, 625, 785, 1418, 593, 668, 1286, 1025, 137, 599, 622, 649, 1313, 687, 778, 1261, 524, 256, 952, 879, 650, 553, 1033, 473, 818, 1412, 257, 685, 977, 641, 529, 263, 937, 1413, 809, 609, 151, 1194, 849, 1073, 657, 849, 642, 266, 1161, 1129, 1017, 876, 577, 874, 745, 1026, 1065, 577, 832, 330, 632, 545, 1161, 215, 1177, 885, 1193, 345, 489, 617, 472, 489, 1033, 1038, 625, 344, 849, 609, 1059, 408, 1202, 561, 1145, 904, 655, 1475, 1031, 1715, 1473, 1037, 1071, 657, 931, 929, 889, 841, 561, 737, 472, 929, 720, 705, 679, 143, 656, 905, 641, 1087, 861, 443, 912, 641, 1758, 825, 817, 795, 1082, 826, 713, 849, 1073, 399, 376, 791, 1089, 857, 939, 457, 527, 1137, 265, 1317, 786, 808, 657, 545, 1105, 711, 825, 801, 1179, 264, 539, 795, 801, 450, 945, 572, 501, 853, 665, 841, 1201, 324, 653, 729, 1169, 570, 1098, 1122, 817, 804, 143, 815, 1593, 278, 954, 1044, 777, 961, 593, 731, 548, 1018, 873, 521, 1065, 640, 641, 659, 1042, 1001, 525, 697, 719, 737, 1018, 601, 463, 790, 825, 597, 1060, 953, 2273, 504, 585, 439, 829, 693, 1039, 1289, 618, 557, 1217, 491, 977, 664, 825, 697, 1240, 1081, 1403, 743, 496, 513, 641, 985, 1321, 506, 1068, 1009, 809, 1145, 996, 577, 1449, 161, 1000, 753, 1000, 767, 1319, 279, 785, 481, 1097, 976, 1178, 654, 401, 953, 601, 1037, 545, 940, 1281, 514, 1057, 1057, 982, 785, 1685, 562, 630, 449, 893, 761, 1049, 353, 985, 467, 928, 689, 753, 930, 647, 392, 748, 641, 1353, 653, 1016, 605, 761, 553, 957, 449, 957, 881, 1289, 915, 802, 876, 979, 268, 980, 792, 963, 1237, 601, 850, 770, 849, 521, 889, 137, 212, 817, 595, 915, 427, 825, 903, 923, 1104, 973, 1017, 929, 514, 905, 197, 193, 1281, 752, 435, 881, 1361, 614, 1222, 1017, 613, 873, 953, 713, 1089, 769, 833, 953, 891, 825, 493, 1536, 901, 129, 1169, 655, 1442, 931, 1285, 345, 294, 815, 337, 2182, 541, 505, 1155, 641, 949, 1442, 849, 905, 1033, 1449, 257, 1041, 701, 568, 1093, 144, 771, 568, 567, 689, 195, 1093, 569, 1027, 1506, 898, 151, 840, 609, 826, 1049, 585, 905, 505, 1073, 609, 741, 929, 688, 1625, 574, 743, 2187, 985, 745, 146, 422, 785, 686, 437, 935, 690, 969, 1201, 841, 553, 808, 753, 1341, 760, 517, 553, 1026, 697, 1633, 719, 838, 488, 137, 833, 529, 447, 552, 301, 881, 763, 841, 113, 1337, 615, 1217, 953, 674, 324, 730, 791, 1257, 905, 553, 707, 685, 486, 948, 1021, 876, 897, 981, 1611, 961, 985, 798, 246, 425, 1281, 755, 873, 565, 151, 977, 869, 928, 577, 797, 730, 761, 983, 376, 129, 923, 1037, 609, 819, 705, 841, 725, 913, 129, 1453, 801, 961, 1341, 793, 865, 505, 647, 952, 553, 905, 937, 857, 1032, 161, 519, 769, 143, 1155, 623, 817, 961, 1129, 729, 137, 891, 1683, 703, 1081, 785, 761, 801, 905, 1497, 939, 1388, 559, 681, 873, 1538, 697, 1083, 497, 730, 113, 1082, 593, 1001, 892, 889, 525, 732, 752, 738, 151, 897, 1329, 745, 1560, 553, 577, 801, 1285, 901, 545, 769, 1202, 989, 770, 1145, 773, 697, 212, 633, 295, 552, 993, 619, 97, 443, 633, 929, 584, 1473, 529, 1217, 553, 2017, 975, 1056, 696, 874, 593, 913, 1460, 577, 561, 870, 1033, 961, 849, 945, 1128, 886, 1063, 993, 616, 1576, 1095, 569, 235, 697, 1106, 703, 721, 945, 846, 1498, 1027, 1791, 633, 473, 569, 707, 865, 1353, 1595, 1162, 1177, 345, 799, 1073, 985, 401, 289, 487, 945, 982, 907, 479, 833, 161, 857, 847, 729, 1246, 1004, 673, 1025, 674, 1502, 700, 657, 698, 901, 195, 819, 129, 485, 593, 876, 529, 777, 1179, 1223, 539, 1105, 430, 1181, 703, 961, 1138, 316, 197, 1385, 737, 541, 609, 504, 746, 457, 164, 137, 97, 577, 385, 1094, 593, 1161, 460, 897, 889, 320, 440, 895, 873, 625, 1025, 770, 469, 441, 152, 737, 1081, 1017, 1145, 673, 1361, 196, 1248, 565, 1281, 737, 1867, 581, 446, 333, 143, 729, 1042, 650, 593, 753, 744, 209, 1113, 1090, 1025, 739, 961, 1095, 1161, 601, 517, 937, 914, 1073, 687, 1001, 662, 577, 553, 264, 891, 932, 866, 266, 1033, 672, 873, 777, 2066, 775, 674, 866, 1235, 420, 1130, 770, 427, 1506, 139, 741, 313, 1002, 1029, 1201, 299, 161, 638, 857, 897, 573, 441, 306, 1800]\n",
            "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)\n"
          ]
        }
      ],
      "source": [
        "# Stack of the pianorolls and list of lengths\n",
        "\n",
        "pianoroll_lengths = [e.size()[1] for e in combined_pianorolls]\n",
        "#print(combined_pianorolls.size()[1])\n",
        "#print(pianoroll_lengths)\n",
        "combined_pianorolls = torch.hstack(combined_pianorolls)\n",
        "#print(combined_pianorolls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEcmnjJdKVBF"
      },
      "source": [
        "\n",
        "\n",
        "The code for saving the results obtained in two .pt files is given below. These files will be used during generation to retrieve the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iH0KCy1XZFC9",
        "outputId": "6d90daa4-519d-4576-b35d-1c738b126c44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1018,  763,  845,  863,  129,  743, 1089, 1117, 1297,  658,  177,  825,\n",
            "         977,  465,  697,  747, 1113,  993, 1105,  974,  525, 1560,  881,  441,\n",
            "         671, 1297,  473,  911,  593,  793,  737, 1097,  590,  665, 1159,  841,\n",
            "         649,  779,  669,  573,  617, 1206,  733,  818, 1681,  585,  156,  739,\n",
            "        1358, 1411,  711,  640,  473,  932, 1265, 1113,  805,  545,  906,  926,\n",
            "        1345,  609,  601,  161, 1040,  675,  651,  867, 1049,  625, 1049,  875,\n",
            "         743, 1099,  193,  922,  689, 1145,  753,  853,  935,  914,  817,  193,\n",
            "        1026,  129,  905,  126,  949, 1000, 1185,  653, 1115,  129,  977,  392,\n",
            "         872,  971,  561,  361,  841, 1087,  715, 2153, 2187, 1233,  497,  615,\n",
            "         808, 1003, 1009, 1266,  721, 1208,  633,  345,  489,  838,  487, 2273,\n",
            "         817,  664,  361,  923,  768,  709,  869,  765, 1306,  545,  939,  481,\n",
            "        1369,  485,  801,  887,  888,  985, 1078, 1001, 1371,  841, 1045,  841,\n",
            "         474,  561, 1007,  577,  992, 1037,  706,  672,  889,  969, 1161,  390,\n",
            "         557, 1033,  345,  977, 1369, 1361, 1285,  561,   97, 1113,  569, 1117,\n",
            "         753,  944, 1053,  504,  735,  624,  297, 1362, 1385,  336,  944,  504,\n",
            "         857,  698,  733,  825,  907, 1155,  129,  785,  570, 1009,  760, 1094,\n",
            "         907,  886,  791, 1185, 1115,  978,  289,  513,  987,  608,  849,  745,\n",
            "         441,  536,  431,  557,  344,  907,  711,  993,  895,  616,  332,  299,\n",
            "         793, 1033,  913,  698,  322,  829,  453, 1095, 1634,  633, 1209, 1102,\n",
            "         873,  962,  647,  129,  904,  737,  361,  335,  769,  882,  609,  791,\n",
            "         681,  706,  430,  399,  865, 1203,  723,  861, 1266,  585, 1115,  737,\n",
            "        1096, 1155,  540,  676,  953,  625,  785, 1418,  593,  668, 1286, 1025,\n",
            "         137,  599,  622,  649, 1313,  687,  778, 1261,  524,  256,  952,  879,\n",
            "         650,  553, 1033,  473,  818, 1412,  257,  685,  977,  641,  529,  263,\n",
            "         937, 1413,  809,  609,  151, 1194,  849, 1073,  657,  849,  642,  266,\n",
            "        1161, 1129, 1017,  876,  577,  874,  745, 1026, 1065,  577,  832,  330,\n",
            "         632,  545, 1161,  215, 1177,  885, 1193,  345,  489,  617,  472,  489,\n",
            "        1033, 1038,  625,  344,  849,  609, 1059,  408, 1202,  561, 1145,  904,\n",
            "         655, 1475, 1031, 1715, 1473, 1037, 1071,  657,  931,  929,  889,  841,\n",
            "         561,  737,  472,  929,  720,  705,  679,  143,  656,  905,  641, 1087,\n",
            "         861,  443,  912,  641, 1758,  825,  817,  795, 1082,  826,  713,  849,\n",
            "        1073,  399,  376,  791, 1089,  857,  939,  457,  527, 1137,  265, 1317,\n",
            "         786,  808,  657,  545, 1105,  711,  825,  801, 1179,  264,  539,  795,\n",
            "         801,  450,  945,  572,  501,  853,  665,  841, 1201,  324,  653,  729,\n",
            "        1169,  570, 1098, 1122,  817,  804,  143,  815, 1593,  278,  954, 1044,\n",
            "         777,  961,  593,  731,  548, 1018,  873,  521, 1065,  640,  641,  659,\n",
            "        1042, 1001,  525,  697,  719,  737, 1018,  601,  463,  790,  825,  597,\n",
            "        1060,  953, 2273,  504,  585,  439,  829,  693, 1039, 1289,  618,  557,\n",
            "        1217,  491,  977,  664,  825,  697, 1240, 1081, 1403,  743,  496,  513,\n",
            "         641,  985, 1321,  506, 1068, 1009,  809, 1145,  996,  577, 1449,  161,\n",
            "        1000,  753, 1000,  767, 1319,  279,  785,  481, 1097,  976, 1178,  654,\n",
            "         401,  953,  601, 1037,  545,  940, 1281,  514, 1057, 1057,  982,  785,\n",
            "        1685,  562,  630,  449,  893,  761, 1049,  353,  985,  467,  928,  689,\n",
            "         753,  930,  647,  392,  748,  641, 1353,  653, 1016,  605,  761,  553,\n",
            "         957,  449,  957,  881, 1289,  915,  802,  876,  979,  268,  980,  792,\n",
            "         963, 1237,  601,  850,  770,  849,  521,  889,  137,  212,  817,  595,\n",
            "         915,  427,  825,  903,  923, 1104,  973, 1017,  929,  514,  905,  197,\n",
            "         193, 1281,  752,  435,  881, 1361,  614, 1222, 1017,  613,  873,  953,\n",
            "         713, 1089,  769,  833,  953,  891,  825,  493, 1536,  901,  129, 1169,\n",
            "         655, 1442,  931, 1285,  345,  294,  815,  337, 2182,  541,  505, 1155,\n",
            "         641,  949, 1442,  849,  905, 1033, 1449,  257, 1041,  701,  568, 1093,\n",
            "         144,  771,  568,  567,  689,  195, 1093,  569, 1027, 1506,  898,  151,\n",
            "         840,  609,  826, 1049,  585,  905,  505, 1073,  609,  741,  929,  688,\n",
            "        1625,  574,  743, 2187,  985,  745,  146,  422,  785,  686,  437,  935,\n",
            "         690,  969, 1201,  841,  553,  808,  753, 1341,  760,  517,  553, 1026,\n",
            "         697, 1633,  719,  838,  488,  137,  833,  529,  447,  552,  301,  881,\n",
            "         763,  841,  113, 1337,  615, 1217,  953,  674,  324,  730,  791, 1257,\n",
            "         905,  553,  707,  685,  486,  948, 1021,  876,  897,  981, 1611,  961,\n",
            "         985,  798,  246,  425, 1281,  755,  873,  565,  151,  977,  869,  928,\n",
            "         577,  797,  730,  761,  983,  376,  129,  923, 1037,  609,  819,  705,\n",
            "         841,  725,  913,  129, 1453,  801,  961, 1341,  793,  865,  505,  647,\n",
            "         952,  553,  905,  937,  857, 1032,  161,  519,  769,  143, 1155,  623,\n",
            "         817,  961, 1129,  729,  137,  891, 1683,  703, 1081,  785,  761,  801,\n",
            "         905, 1497,  939, 1388,  559,  681,  873, 1538,  697, 1083,  497,  730,\n",
            "         113, 1082,  593, 1001,  892,  889,  525,  732,  752,  738,  151,  897,\n",
            "        1329,  745, 1560,  553,  577,  801, 1285,  901,  545,  769, 1202,  989,\n",
            "         770, 1145,  773,  697,  212,  633,  295,  552,  993,  619,   97,  443,\n",
            "         633,  929,  584, 1473,  529, 1217,  553, 2017,  975, 1056,  696,  874,\n",
            "         593,  913, 1460,  577,  561,  870, 1033,  961,  849,  945, 1128,  886,\n",
            "        1063,  993,  616, 1576, 1095,  569,  235,  697, 1106,  703,  721,  945,\n",
            "         846, 1498, 1027, 1791,  633,  473,  569,  707,  865, 1353, 1595, 1162,\n",
            "        1177,  345,  799, 1073,  985,  401,  289,  487,  945,  982,  907,  479,\n",
            "         833,  161,  857,  847,  729, 1246, 1004,  673, 1025,  674, 1502,  700,\n",
            "         657,  698,  901,  195,  819,  129,  485,  593,  876,  529,  777, 1179,\n",
            "        1223,  539, 1105,  430, 1181,  703,  961, 1138,  316,  197, 1385,  737,\n",
            "         541,  609,  504,  746,  457,  164,  137,   97,  577,  385, 1094,  593,\n",
            "        1161,  460,  897,  889,  320,  440,  895,  873,  625, 1025,  770,  469,\n",
            "         441,  152,  737, 1081, 1017, 1145,  673, 1361,  196, 1248,  565, 1281,\n",
            "         737, 1867,  581,  446,  333,  143,  729, 1042,  650,  593,  753,  744,\n",
            "         209, 1113, 1090, 1025,  739,  961, 1095, 1161,  601,  517,  937,  914,\n",
            "        1073,  687, 1001,  662,  577,  553,  264,  891,  932,  866,  266, 1033,\n",
            "         672,  873,  777, 2066,  775,  674,  866, 1235,  420, 1130,  770,  427,\n",
            "        1506,  139,  741,  313, 1002, 1029, 1201,  299,  161,  638,  857,  897,\n",
            "         573,  441,  306, 1800])\n"
          ]
        }
      ],
      "source": [
        "# Saving files\n",
        "\n",
        "torch.save(combined_pianorolls, os.path.join(root_dir, 'Lakh Piano Dataset', '10000_pianorolls.pt'))\n",
        "pianoroll_lengths = torch.tensor(pianoroll_lengths)\n",
        "#print(pianoroll_lengths)\n",
        "torch.save(pianoroll_lengths, os.path.join(root_dir, 'Lakh Piano Dataset', '10000_pianorolls_lengths.pt'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
